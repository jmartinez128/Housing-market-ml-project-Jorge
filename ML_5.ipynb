{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50a9f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    import sklearn\n",
    "    from sklearn import tree, model_selection, metrics\n",
    "except ImportError:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scikit-learn\"])\n",
    "\n",
    "\n",
    "file_path = '/Users/jorgemartinez/Documents/NYDSA #3 Machine Learning Project/Machine Learning Project Proposal/Ames_HousePrice.csv'\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8674cde2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 1 unnamed columns and PID\n",
      "DataFrame shape after dropping columns: (2580, 80)\n"
     ]
    }
   ],
   "source": [
    "# First, let's drop columns that are unnamed or have no meaning, and also drop PID\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Identify unnamed columns and PID\n",
    "unnamed_cols = [col for col in df.columns if 'unnamed' in col.lower() or 'no meaning' in col.lower()]\n",
    "columns_to_drop = unnamed_cols + ['PID']\n",
    "\n",
    "# Drop identified columns\n",
    "df_cleaned = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "print(f\"Dropped {len(unnamed_cols)} unnamed columns and PID\")\n",
    "print(f\"DataFrame shape after dropping columns: {df_cleaned.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7eeb8790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical variables where NA means something specific\n",
    "meaningful_na_columns = ['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', \n",
    "                        'BsmtFinType1', 'BsmtFinType2', 'FireplaceQu',\n",
    "                        'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "                        'PoolQC', 'Fence', 'MiscFeature', 'MasVnrType']\n",
    "\n",
    "# Fill NA values in these columns with appropriate labels\n",
    "for col in meaningful_na_columns:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('None')  # Replace NA with 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b68dd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did I come to the conclusion below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99242363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled missing 'Electrical' value with 'SBrkr'\n"
     ]
    }
   ],
   "source": [
    "# Impute the single missing 'Electrical' value with the most common category\n",
    "df['Electrical'] = df['Electrical'].fillna('SBrkr')  # or use df['Electrical'].mode()[0]\n",
    "\n",
    "print(\"Filled missing 'Electrical' value with 'SBrkr'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0764ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing Numerical Columns with 0 for Specific Cases\n",
    "# Step 1: For basement-related measurements\n",
    "for col in ['BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF']:\n",
    "    if col in df.columns:\n",
    "        # Find rows where BsmtQual was originally NA (indicating no basement)\n",
    "        mask = df['BsmtQual'] == 'None'  # Now 'None' after our replacement above\n",
    "        # Fill NAs with 0 for houses with no basement\n",
    "        df.loc[mask, col] = df.loc[mask, col].fillna(0)\n",
    "        # Fill any remaining NAs with 0\n",
    "        df[col] = df[col].fillna(0)\n",
    "\n",
    "# Step 2: For garage-related measurements\n",
    "if 'GarageArea' in df.columns and 'GarageCars' in df.columns:\n",
    "    mask = df['GarageType'] == 'None'  # Now 'None' after our replacement above\n",
    "    # Fill NAs with 0 for houses with no garage\n",
    "    df.loc[mask, 'GarageArea'] = df.loc[mask, 'GarageArea'].fillna(0)\n",
    "    df.loc[mask, 'GarageCars'] = df.loc[mask, 'GarageCars'].fillna(0)\n",
    "    # Fill any remaining NAs with 0\n",
    "    df['GarageArea'] = df['GarageArea'].fillna(0)\n",
    "    df['GarageCars'] = df['GarageCars'].fillna(0)\n",
    "\n",
    "# Step 3: For Masonry veneer area\n",
    "if 'MasVnrArea' in df.columns:\n",
    "    mask = df['MasVnrType'] == 'None'\n",
    "    # Fill NAs with 0 for houses with no masonry veneer\n",
    "    df.loc[mask, 'MasVnrArea'] = df.loc[mask, 'MasVnrArea'].fillna(0)\n",
    "    # Fill any remaining NAs with 0\n",
    "    df['MasVnrArea'] = df['MasVnrArea'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16c9352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review the cell below to make sure the imputation worked as expected\n",
    "# Make sure there aren't any features left with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5047fbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns with no missing values: (2580, 35)\n",
      "Categorical columns: (2580, 43)\n"
     ]
    }
   ],
   "source": [
    "# Select numerical columns\n",
    "df_columns = df.select_dtypes(include='number')\n",
    "\n",
    "# Drop numerical columns with any REMAINING missing values\n",
    "df_columns_no_na = df_columns.dropna(axis=1)\n",
    "\n",
    "# Select categorical columns\n",
    "categorical_df = df.select_dtypes(include='object')\n",
    "\n",
    "print(\"Numerical columns with no missing values:\", df_columns_no_na.shape)\n",
    "print(\"Categorical columns:\", categorical_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f101b95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>SWISU</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Fin</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C (all)</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>IDOTRR</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>Po</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>OldTown</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>N</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NWAmes</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Fin</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>BrkSide</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>Fa</td>\n",
       "      <td>Po</td>\n",
       "      <td>P</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>CulDSac</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Edwards</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>RH</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>2Types</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>Fin</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>None</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>SawyerW</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2580 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     MSZoning Street Alley LotShape LandContour Utilities LotConfig LandSlope  \\\n",
       "0          RL   Pave  None      Reg         Lvl    AllPub    Corner       Gtl   \n",
       "1          RL   Pave  None      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "2     C (all)   Pave  None      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "3          RL   Pave  None      Reg         Lvl    AllPub    Corner       Gtl   \n",
       "4          RL   Pave  None      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "...       ...    ...   ...      ...         ...       ...       ...       ...   \n",
       "2575       RL   Pave  None      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "2576       RL   Pave  None      IR1         Lvl    AllPub   CulDSac       Gtl   \n",
       "2577       RH   Pave  None      Reg         HLS    AllPub    Inside       Gtl   \n",
       "2578       RL   Pave  None      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "2579       RL   Pave  None      IR1         Lvl    AllPub    Inside       Gtl   \n",
       "\n",
       "     Neighborhood Condition1  ... GarageType GarageFinish GarageQual  \\\n",
       "0           SWISU       Norm  ...     Detchd          Unf         TA   \n",
       "1         Edwards       Norm  ...     Attchd          Fin         TA   \n",
       "2          IDOTRR       Norm  ...     Detchd          Unf         TA   \n",
       "3         OldTown       Norm  ...     Detchd          Unf         TA   \n",
       "4          NWAmes       Norm  ...     Attchd          Fin         TA   \n",
       "...           ...        ...  ...        ...          ...        ...   \n",
       "2575      BrkSide       Norm  ...     Detchd          Unf         Fa   \n",
       "2576      Edwards       Norm  ...     Attchd          Unf         TA   \n",
       "2577      Crawfor       Norm  ...     2Types          Unf         TA   \n",
       "2578      CollgCr       Norm  ...     Attchd          Fin         TA   \n",
       "2579      SawyerW       Norm  ...     Attchd          RFn         TA   \n",
       "\n",
       "     GarageCond PavedDrive PoolQC Fence MiscFeature SaleType SaleCondition  \n",
       "0            TA          Y   None  None        None      WD         Normal  \n",
       "1            TA          Y   None  None        None      WD         Normal  \n",
       "2            Po          N   None  None        None      WD         Normal  \n",
       "3            TA          N   None  None        None      WD         Normal  \n",
       "4            TA          Y   None  None        None      WD         Normal  \n",
       "...         ...        ...    ...   ...         ...      ...           ...  \n",
       "2575         Po          P   None  None        None      WD         Normal  \n",
       "2576         TA          Y   None  None        None      WD         Normal  \n",
       "2577         TA          Y   None  None        None      WD         Normal  \n",
       "2578         TA          Y   None  None        None      WD         Normal  \n",
       "2579         TA          Y   None  None        None      WD         Normal  \n",
       "\n",
       "[2580 rows x 43 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a918c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "#See which categorical columns are ordinal versus nominal (ordinal ones get encded normally, \n",
    "#nominal ones have to get specifically encoded in the way they are ranked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "427bd199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns\n",
    "categorical_df = df.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ea8970e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mroe docstring to the below to make it clearer what I am doing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd1b85d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filled LotFrontage missing values with median: 68.0\n",
      "\n",
      "Statistics for houses with garages but missing GarageYrBlt:\n",
      "Number of houses: 2\n",
      "Details of these houses:\n",
      "House 1 (Index 433):\n",
      "  GarageType: Detchd\n",
      "  YearBuilt: 1923\n",
      "  GarageArea: 0.0\n",
      "  GarageCars: 0.0\n",
      "House 2 (Index 531):\n",
      "  GarageType: Detchd\n",
      "  YearBuilt: 1910\n",
      "  GarageArea: 360.0\n",
      "  GarageCars: 1.0\n",
      "\n",
      "GarageType distribution for these houses:\n",
      "  Detchd: 2 houses\n",
      "\n",
      "Filled GarageYrBlt for 2 houses with garages using median: 1978.0\n",
      "Filled GarageYrBlt for 127 houses without garages with 0\n",
      "\n",
      "Missing values after imputation:\n",
      "LotFrontage     0\n",
      "BsmtFullBath    0\n",
      "BsmtHalfBath    0\n",
      "GarageYrBlt     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Impute missing values for specific columns\n",
    "\n",
    "# 1. LotFrontage - impute using overall median\n",
    "lot_frontage_median = df['LotFrontage'].median()\n",
    "df['LotFrontage'] = df['LotFrontage'].fillna(lot_frontage_median)\n",
    "print(f\"Filled LotFrontage missing values with median: {lot_frontage_median}\")\n",
    "\n",
    "# 2. Basement bathrooms - fill with 0\n",
    "df['BsmtFullBath'] = df['BsmtFullBath'].fillna(0)\n",
    "df['BsmtHalfBath'] = df['BsmtHalfBath'].fillna(0)\n",
    "\n",
    "#Remove the eda code below\n",
    "# 3. GarageYrBlt - fill differently based on GarageType\n",
    "# First, get some statistics about houses with garages and missing GarageYrBlt\n",
    "mask_has_garage_missing_yr = (df['GarageType'] != 'None') & (df['GarageYrBlt'].isna())\n",
    "houses_with_garage_missing_yr = df[mask_has_garage_missing_yr]\n",
    "count_has_garage_missing_yr = len(houses_with_garage_missing_yr)\n",
    "\n",
    "print(f\"\\nStatistics for houses with garages but missing GarageYrBlt:\")\n",
    "print(f\"Number of houses: {count_has_garage_missing_yr}\")\n",
    "\n",
    "if count_has_garage_missing_yr > 0:\n",
    "    print(\"Details of these houses:\")\n",
    "    for i, (idx, row) in enumerate(houses_with_garage_missing_yr.iterrows()):\n",
    "        print(f\"House {i+1} (Index {idx}):\")\n",
    "        print(f\"  GarageType: {row['GarageType']}\")\n",
    "        print(f\"  YearBuilt: {row['YearBuilt']}\")\n",
    "        print(f\"  GarageArea: {row['GarageArea']}\")\n",
    "        print(f\"  GarageCars: {row['GarageCars']}\")\n",
    "    \n",
    "    # Get garage type distribution\n",
    "    garage_type_counts = houses_with_garage_missing_yr['GarageType'].value_counts()\n",
    "    print(f\"\\nGarageType distribution for these houses:\")\n",
    "    for garage_type, count in garage_type_counts.items():\n",
    "        print(f\"  {garage_type}: {count} houses\")\n",
    "\n",
    "# Now impute the missing values\n",
    "if count_has_garage_missing_yr > 0:\n",
    "    # Calculate median from houses that have garages\n",
    "    garage_yr_median = df[df['GarageType'] != 'None']['GarageYrBlt'].median()\n",
    "    df.loc[mask_has_garage_missing_yr, 'GarageYrBlt'] = garage_yr_median\n",
    "    print(f\"\\nFilled GarageYrBlt for {count_has_garage_missing_yr} houses with garages using median: {garage_yr_median}\")\n",
    "\n",
    "# For houses with no garage, use 0\n",
    "mask_no_garage = (df['GarageType'] == 'None') & (df['GarageYrBlt'].isna())\n",
    "count_no_garage = mask_no_garage.sum()\n",
    "df.loc[mask_no_garage, 'GarageYrBlt'] = 0\n",
    "print(f\"Filled GarageYrBlt for {count_no_garage} houses without garages with 0\")\n",
    "\n",
    "# Check if we've addressed the missing values in our target columns\n",
    "check_cols = ['LotFrontage', 'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt']\n",
    "missing_counts = df[check_cols].isna().sum()\n",
    "print(\"\\nMissing values after imputation:\")\n",
    "print(missing_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28379cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code below shows that we don't have any missing values left at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c1a276bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9cae9456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For below:  THe feature you dropped is one you reference, but computationally it does not matter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5d9b2b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "def drop_most_frequent_category(df_cat):\n",
    "    new_df = pd.DataFrame()\n",
    "    for col in df_cat.columns:\n",
    "        counts = df_cat[col].value_counts()\n",
    "        # Get the most frequent category\n",
    "        drop_cat = counts.idxmax()\n",
    "\n",
    "        # Perform one-hot encoding and drop the most frequent category\n",
    "        dummies = pd.get_dummies(df_cat[col], prefix=col)\n",
    "        dummies = dummies.drop(f\"{col}_{drop_cat}\", axis=1)\n",
    "\n",
    "        new_df = pd.concat([new_df, dummies], axis=1)\n",
    "    return new_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "77f75248",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after encoding categorical variables: (2580, 231)\n"
     ]
    }
   ],
   "source": [
    "# Apply the custom one-hot encoding\n",
    "categorical_encoded = drop_most_frequent_category(categorical_df)\n",
    "\n",
    "print(\"Shape after encoding categorical variables:\", categorical_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3a525bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape of X: (2580, 265)\n"
     ]
    }
   ],
   "source": [
    "X = pd.concat([df_columns_no_na.drop(columns=['SalePrice'], errors='ignore'),\n",
    "               categorical_encoded], axis=1)\n",
    "\n",
    "# Target variable\n",
    "y = df['SalePrice']\n",
    "\n",
    "print(\"Final shape of X:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3c9df3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set up 5-fold cross-validation\n",
    "n_folds = 5\n",
    "kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26a1be41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for cross-validation\n",
    "def evaluate_model_cv(model, X, y):\n",
    "    # Get R² scores\n",
    "    r2_scores = cross_val_score(model, X, y, cv=5, scoring='r2')\n",
    "    \n",
    "    # Get RMSE scores\n",
    "    mse_scores = -cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "    rmse_scores = np.sqrt(mse_scores)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"Average RMSE: ${rmse_scores.mean():,.2f}\")\n",
    "    print(f\"Average R²: {r2_scores.mean():.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    return {\n",
    "        'model_name': model.__class__.__name__,\n",
    "        'rmse_mean': rmse_scores.mean(),\n",
    "        'r2_mean': r2_scores.mean()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1d89c8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multiple Linear Regression:\n",
      "Model: LinearRegression\n",
      "Average RMSE: $22,746.18\n",
      "Average R²: 0.9068\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. Multiple Linear Regression with cross-validation\n",
    "print(\"Multiple Linear Regression:\")\n",
    "mlr = LinearRegression()\n",
    "mlr_results = evaluate_model_cv(mlr, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ec60122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression (alpha=1.0):\n",
      "Model: Ridge\n",
      "Average RMSE: $21,862.91\n",
      "Average R²: 0.9138\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=8.78534e-21): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=9.4342e-21): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=8.92009e-21): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=9.72893e-21): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=8.69977e-21): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=8.78534e-21): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=9.4342e-21): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=8.92009e-21): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=9.72893e-21): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/scipy/_lib/_util.py:1233: LinAlgWarning: Ill-conditioned matrix (rcond=8.69977e-21): result may not be accurate.\n",
      "  return f(*arrays, *other_args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 2. Ridge Regression with cross-validation\n",
    "print(\"Ridge Regression (alpha=1.0):\")\n",
    "ridge = Ridge(alpha=1.0) \n",
    "ridge_results = evaluate_model_cv(ridge, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d3457072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression (alpha=1):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.504e+11, tolerance: 1.139e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.690e+11, tolerance: 1.184e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.106e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.461e+11, tolerance: 1.217e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.398e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Lasso\n",
      "Average RMSE: $22,991.88\n",
      "Average R²: 0.9042\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.106e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.504e+11, tolerance: 1.139e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.690e+11, tolerance: 1.184e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.461e+11, tolerance: 1.217e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.398e+11, tolerance: 1.133e+09\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# 3. Lasso Regression with cross-validation\n",
    "print(\"Lasso Regression (alpha=1):\")\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso_results = evaluate_model_cv(lasso, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed21f7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pre-processing, do separate notebooks for decision treess, random forests, gradient and xgboosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d78eaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DecisionTreeRegressor\n",
      "Average RMSE: $38,836.56\n",
      "Average R²: 0.7301\n",
      "------------------------------\n",
      "Model: RandomForestRegressor\n",
      "Average RMSE: $24,967.57\n",
      "Average R²: 0.8885\n",
      "------------------------------\n",
      "Model: GradientBoostingRegressor\n",
      "Average RMSE: $23,455.31\n",
      "Average R²: 0.9007\n",
      "------------------------------\n",
      "Model: XGBRegressor\n",
      "Average RMSE: $21,946.84\n",
      "Average R²: 0.9134\n",
      "------------------------------\n",
      "\n",
      "Model Comparison (5-fold CV with threading backend):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>rmse_mean</th>\n",
       "      <th>r2_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ridge</td>\n",
       "      <td>21862.909063</td>\n",
       "      <td>0.913821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBRegressor</td>\n",
       "      <td>21946.840027</td>\n",
       "      <td>0.913386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lasso</td>\n",
       "      <td>22592.859707</td>\n",
       "      <td>0.908062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LinearRegression</td>\n",
       "      <td>22746.179244</td>\n",
       "      <td>0.906764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>23455.308049</td>\n",
       "      <td>0.900662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>24967.571171</td>\n",
       "      <td>0.888512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>38836.559523</td>\n",
       "      <td>0.730058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model_name     rmse_mean   r2_mean\n",
       "0                      Ridge  21862.909063  0.913821\n",
       "1               XGBRegressor  21946.840027  0.913386\n",
       "2                      Lasso  22592.859707  0.908062\n",
       "3           LinearRegression  22746.179244  0.906764\n",
       "4  GradientBoostingRegressor  23455.308049  0.900662\n",
       "5      RandomForestRegressor  24967.571171  0.888512\n",
       "6      DecisionTreeRegressor  38836.559523  0.730058"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# Tree-based regressors + cross-validation with THREADING backend\n",
    "\n",
    "# ===============================================================\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score  # k-fold CV helper\n",
    "from sklearn.tree import DecisionTreeRegressor        # single decision tree regressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor  # ensembles\n",
    "from joblib import parallel_backend                   # let us force thread-based parallelism\n",
    "import sys, subprocess                                # used only to auto-install xgboost if missing\n",
    "\n",
    "# 5-fold setup here ---\n",
    "try:\n",
    "    kf  # do we already have it?\n",
    "except NameError:\n",
    "    from sklearn.model_selection import KFold\n",
    "    # KFold controls how CV splits your data. Shuffle for randomness; fix random_state for reproducibility.\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# --- XGBoost is not in scikit-learn, so we import separately and install if needed ---\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except Exception:\n",
    "    # If import fails, install it into the current Python environment, then import.\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"xgboost\"])\n",
    "    import xgboost as xgb\n",
    "\n",
    "# ---------------------------------------------------------------\n",
    "# Helper: cross-validate a model using your same `kf` splits.\n",
    "# We force thread-based parallelism to avoid Python 3.13 cleanup\n",
    "# errors that appear with process-based parallelism.\n",
    "# ---------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model_cv(model, X, y, cv=kf):\n",
    "    \"\"\"\n",
    "    Trains/evaluates `model` with k-fold CV:\n",
    "      - R² (bigger is better; variance explained)\n",
    "      - RMSE (smaller is better; error in target units, e.g., dollars)\n",
    "    Uses joblib's threading backend so you don't hit the 3.13 bug.\n",
    "    \"\"\"\n",
    "    # Force joblib to use threads (not processes) for parallel loops.\n",
    "    # This preserves parallel speedups in most sklearn ops without the cleanup crash.\n",
    "    with parallel_backend(\"threading\"):\n",
    "        # cross_val_score trains/evaluates model across `cv` splits and returns the score for each fold.\n",
    "        # scoring='r2' gives us the R² scores.\n",
    "        r2_scores  = cross_val_score(model, X, y, cv=cv, scoring=\"r2\", n_jobs=-1)\n",
    "\n",
    "        # For RMSE, sklearn offers negative MSE so that \"higher is better\" still holds.\n",
    "        # We negate it back to MSE, then take sqrt to get RMSE.\n",
    "        mse_scores = -cross_val_score(model, X, y, cv=cv, scoring=\"neg_mean_squared_error\", n_jobs=-1)\n",
    "\n",
    "    rmse_scores = np.sqrt(mse_scores)  # convert MSE -> RMSE (same units as SalePrice)\n",
    "\n",
    "    # Nice on-screen summary for you while training.\n",
    "    print(f\"Model: {model.__class__.__name__}\")\n",
    "    print(f\"Average RMSE: ${rmse_scores.mean():,.2f}\")   # money-style formatting\n",
    "    print(f\"Average R²: {r2_scores.mean():.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "    # Return a small dict for the comparison table later.\n",
    "    return {\n",
    "        \"model_name\": model.__class__.__name__,\n",
    "        \"rmse_mean\": float(rmse_scores.mean()),\n",
    "        \"r2_mean\": float(r2_scores.mean()),\n",
    "    }\n",
    "\n",
    "# ============================\n",
    "# Models: defaults + why/when\n",
    "# ============================\n",
    "\n",
    "# 1) Decision Tree (single tree)\n",
    "#    - `max_depth` is the main \"knob\" to prevent overfitting.\n",
    "#    - Lower depth -> simpler tree (higher bias, lower variance).\n",
    "#    - Try values like 3, 5, 7, 10 and see how CV R²/RMSE change.\n",
    "dt = DecisionTreeRegressor(\n",
    "    max_depth=5,     # <- TUNE: increase for more complexity\n",
    "    random_state=42  # reproducible results\n",
    ")\n",
    "dt_results = evaluate_model_cv(dt, X, y, cv=kf)\n",
    "\n",
    "# 2) Random Forest\n",
    "#    - An ensemble of decision trees, trained on bootstrapped samples.\n",
    "#    - Key knobs:\n",
    "#        n_estimators: more trees generally better (to a point), slower training\n",
    "#        max_features: how many features to consider when splitting (\"sqrt\" is common for high-dim)\n",
    "#        min_samples_leaf: increases leaf size => smoother predictions, less overfit\n",
    "#    - NOTE: n_jobs=1 avoids nested processes since our CV already parallelizes with threads.\n",
    "rf = RandomForestRegressor(\n",
    "    n_estimators=300,   # <- TUNE: 200–1000 (tradeoff speed/accuracy)\n",
    "    max_features=\"sqrt\",# <- TUNE: \"sqrt\", \"log2\", or a float (0.3–0.8)\n",
    "    min_samples_leaf=1, # <- TUNE: 1–10; larger reduces overfitting\n",
    "    random_state=42,\n",
    "    n_jobs=1            # avoid process-based forks inside the model\n",
    ")\n",
    "rf_results = evaluate_model_cv(rf, X, y, cv=kf)\n",
    "\n",
    "# 3) Gradient Boosting (scikit-learn)\n",
    "#    - Builds trees sequentially to correct previous errors.\n",
    "#    - Key knobs:\n",
    "#        n_estimators: more boosting rounds (default=100)\n",
    "#        learning_rate: step size per round (smaller -> need more rounds; often 0.05–0.1)\n",
    "#        max_depth or max_leaf_nodes via base_estimator params (controls tree complexity)\n",
    "#    - Good baseline booster without extra installs.\n",
    "gbr = GradientBoostingRegressor(\n",
    "    random_state=42\n",
    "    # <- TUNE: learning_rate=0.05, n_estimators=300, max_depth=3 via max_depth in base tree\n",
    ")\n",
    "gbr_results = evaluate_model_cv(gbr, X, y, cv=kf)\n",
    "\n",
    "# 4) XGBoost Regressor\n",
    "#    - Often stronger/faster with better regularization and handling of sparsity.\n",
    "#    - Key knobs:\n",
    "#        n_estimators: boosting rounds (200–1000 typical)\n",
    "#        learning_rate: 0.03–0.1 common\n",
    "#        max_depth: tree depth (3–10 typical; 6 is a sweet spot often)\n",
    "#        subsample, colsample_bytree: stochasticity to reduce overfit (0.5–0.9 typical)\n",
    "#        reg_lambda, reg_alpha: L2 / L1 regularization\n",
    "#    - NOTE: n_jobs=1 to avoid nested processes.\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=500,        # <- TUNE: try 300–1000 with matching learning_rate\n",
    "    learning_rate=0.05,      # <- TUNE: 0.03–0.1; lower needs more n_estimators\n",
    "    max_depth=6,             # <- TUNE: 3–10 depending on data complexity\n",
    "    subsample=0.8,           # <- TUNE: 0.6–0.9; lower can reduce overfitting\n",
    "    colsample_bytree=0.8,    # <- TUNE: 0.6–0.9; feature subsampling\n",
    "    objective=\"reg:squarederror\",\n",
    "    reg_lambda=1.0,          # <- TUNE: increase if overfitting\n",
    "    random_state=42,\n",
    "    n_jobs=1                 # avoid nested process-based parallelism\n",
    ")\n",
    "xgb_results = evaluate_model_cv(xgb_model, X, y, cv=kf)\n",
    "\n",
    "# ==========================================\n",
    "# Combine with your earlier linear models\n",
    "# (mlr_results, ridge_results, lasso_results)\n",
    "# ==========================================\n",
    "all_results = [\n",
    "    mlr_results, ridge_results, lasso_results,  # from your earlier cell\n",
    "    dt_results, rf_results, gbr_results, xgb_results\n",
    "]\n",
    "\n",
    "# Make a clean comparison table sorted by R² (bigger is better).\n",
    "results_df = pd.DataFrame(all_results).sort_values(\"r2_mean\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\nModel Comparison (5-fold CV with threading backend):\")\n",
    "display(results_df)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# What to adjust next (quick guide):\n",
    "#   - If train scores >> CV scores: you're likely overfitting → reduce max_depth,\n",
    "#     increase min_samples_leaf, add regularization (XGB: raise reg_lambda, lower max_depth),\n",
    "#     or add more data.\n",
    "#   - If both train & CV are low: underfitting → allow more complexity\n",
    "#     (deeper trees, more estimators, higher learning rate—but carefully).\n",
    "#   - If runtime is too long: reduce n_estimators first.\n",
    "# ----------------------------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
